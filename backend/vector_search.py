"""
ë²¡í„° ê²€ìƒ‰ ìœ í‹¸ë¦¬í‹°
FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""
import pickle
from pathlib import Path
from typing import List, Dict, Any
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer


class VectorSearch:
    """ë²¡í„° ê²€ìƒ‰ í´ë˜ìŠ¤"""
    
    def __init__(self, index_dir: str = "vector_db"):
        """
        Args:
            index_dir: FAISS ì¸ë±ìŠ¤ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        """
        self.index_dir = Path(index_dir)
        self.index = None
        self.chunks = None
        self.model = None
        
    def load(self):
        """FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        index_file = self.index_dir / "faiss_index.bin"
        metadata_file = self.index_dir / "chunks_metadata.pkl"
        
        if not index_file.exists():
            raise FileNotFoundError(
                f"FAISS ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_file}\n"
                f"ë¨¼ì € vectorize_data.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”."
            )
        
        if not metadata_file.exists():
            raise FileNotFoundError(
                f"ë©”íƒ€ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {metadata_file}"
            )
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        self.index = faiss.read_index(str(index_file))
        print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {self.index.ntotal}ê°œ ë²¡í„°")
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(metadata_file, "rb") as f:
            self.chunks = pickle.load(f)
        print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.chunks)}ê°œ ì²­í¬")
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ë²¡í„°í™”í•  ë•Œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•œ ëª¨ë¸)
        model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        print(f"ğŸ“¦ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
        self.model = SentenceTransformer(model_name)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (í…ìŠ¤íŠ¸, ë©”íƒ€ë°ì´í„°, ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
        """
        if self.index is None or self.model is None:
            raise RuntimeError("ë¨¼ì € load() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        
        # ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_vector = self.model.encode([query], convert_to_numpy=True)
        query_vector = query_vector.astype('float32')
        
        # FAISSë¡œ ê²€ìƒ‰
        distances, indices = self.index.search(query_vector, top_k)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        results = []
        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
            if idx < len(self.chunks):
                chunk = self.chunks[idx]
                results.append({
                    "rank": i + 1,
                    "text": chunk["text"],
                    "metadata": chunk["metadata"],
                    "distance": float(distance),
                    "similarity": float(1 / (1 + distance))  # ìœ ì‚¬ë„ ì ìˆ˜ (0~1)
                })
        
        return results
    
    def search_by_subject(self, query: str, subject_filter: str = None, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • êµê³¼ëª©ìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            subject_filter: í•„í„°ë§í•  êµê³¼ëª© ì´ë¦„ (Noneì´ë©´ ì „ì²´ ê²€ìƒ‰)
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ë¨¼ì € ì „ì²´ ê²€ìƒ‰
        all_results = self.search(query, top_k * 3)  # í•„í„°ë§ì„ ê³ ë ¤í•´ ë” ë§ì´ ê²€ìƒ‰
        
        if subject_filter:
            # êµê³¼ëª©ìœ¼ë¡œ í•„í„°ë§
            filtered_results = [
                r for r in all_results 
                if subject_filter.lower() in r["metadata"].get("subject", "").lower()
            ]
            return filtered_results[:top_k]
        
        return all_results[:top_k]
    
    def get_context_for_llm(self, query: str, top_k: int = 3) -> str:
        """
        LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ì‚¬ìš©í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        results = self.search(query, top_k)
        
        if not results:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        for i, result in enumerate(results, 1):
            subject = result["metadata"].get("subject", "ì•Œ ìˆ˜ ì—†ìŒ")
            text = result["text"]
            context_parts.append(f"[ë¬¸ì„œ {i}] {subject}\n{text}\n")
        
        return "\n".join(context_parts)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (FastAPIì—ì„œ ì¬ì‚¬ìš©)
_vector_search_instance = None


def get_vector_search(index_dir: str = None) -> VectorSearch:
    """
    VectorSearch ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        index_dir: FAISS ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        
    Returns:
        VectorSearch ì¸ìŠ¤í„´ìŠ¤
    """
    global _vector_search_instance
    
    if _vector_search_instance is None:
        if index_dir is None:
            index_dir = Path(__file__).parent / "vector_db"
        
        _vector_search_instance = VectorSearch(index_dir)
        _vector_search_instance.load()
    
    return _vector_search_instance


if __name__ == "__main__":
    """í…ŒìŠ¤íŠ¸ ì½”ë“œ"""
    print("=" * 60)
    print("ğŸ” ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # VectorSearch ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    vs = VectorSearch()
    vs.load()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "Cì–¸ì–´ ìˆ˜ì—…ì€ ëˆ„ê°€ ê°€ë¥´ì¹˜ë‚˜ìš”?",
        "í”„ë¡œê·¸ë˜ë° ê³¼ëª©ì˜ í‰ê°€ ë°©ë²•ì€?",
        "1ì£¼ì°¨ì—ëŠ” ë¬´ì—‡ì„ ë°°ìš°ë‚˜ìš”?"
    ]
    
    for query in test_queries:
        print(f"\nğŸ“ ì§ˆë¬¸: {query}")
        print("-" * 60)
        
        results = vs.search(query, top_k=3)
        
        for result in results:
            print(f"\n[ìˆœìœ„ {result['rank']}] ìœ ì‚¬ë„: {result['similarity']:.3f}")
            print(f"êµê³¼ëª©: {result['metadata'].get('subject', 'N/A')}")
            print(f"íƒ€ì…: {result['metadata'].get('type', 'N/A')}")
            print(f"ë‚´ìš©: {result['text'][:200]}...")
    
    print("\n" + "=" * 60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)

